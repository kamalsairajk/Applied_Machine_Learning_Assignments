{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: ML Engineering 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your name and UFL email address\n",
    "name = 'Kamal Sai Raj Kuncha'\n",
    "email = 'k.kuncha@ufl.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 2 -- name: Kamal Sai Raj Kuncha, email: k.kuncha@ufl.edu\n",
      "\n",
      "### Python version: 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)]\n",
      "### NumPy version: 1.19.5\n",
      "### Scikit-learn version: 0.24.0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "if name == 'enter your name' or email == 'enter your email':\n",
    "    assert False, 'Enter your name & email first!'\n",
    "else:\n",
    "    print('Assignment 2 -- name: {}, email: {}\\n'.format(name, email))\n",
    "    \n",
    "    # Load packages we need\n",
    "    import sys\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import sklearn\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "    # Let's check our software versions\n",
    "    print('### Python version: ' + __import__('sys').version)\n",
    "    print('### NumPy version: ' + np.__version__)\n",
    "    print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "    print('------------')\n",
    "\n",
    "\n",
    "    # load our packages / code\n",
    "    sys.path.insert(1, '../common/')\n",
    "    import utils\n",
    "    import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters to control behavior of the pre-processing, ML, analysis, etc.\n",
    "seed = 42\n",
    "\n",
    "# deterministic seed for reproducibility\n",
    "##rng = np.random.default_rng(seed)  # best practice but not fully implemented in scikit-learn\n",
    "np.random.seed(seed)\n",
    "\n",
    "prop_vec = [16, 2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In this case, we'll directly load the Adult dataset pre-processed in a similar way as for assignment 1\n",
    "### and we'll immediately split it into train, test, validation.\n",
    "\n",
    "train_x, train_y, test_x, test_y, val_x, val_y, features, labels = utils.load_preproc_adult(prop_vec=prop_vec, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (36178, 88), (36178,)\n",
      "Test: (4523, 88), (4523,)\n",
      "Validation: (4521, 88), (4521,)\n"
     ]
    }
   ],
   "source": [
    "# check that we have what we expect\n",
    "print('Training: {}, {}'.format(train_x.shape, train_y.shape))\n",
    "print('Test: {}, {}'.format(test_x.shape, test_y.shape))\n",
    "print('Validation: {}, {}'.format(val_x.shape, val_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['age', 'workclass_0', 'workclass_1', 'workclass_2', 'workclass_3', 'workclass_4', 'workclass_5', 'workclass_6', 'workclass_7', 'education-num', 'marital-status_0', 'marital-status_1', 'marital-status_2', 'marital-status_3', 'marital-status_4', 'marital-status_5', 'marital-status_6', 'occupation_0', 'occupation_1', 'occupation_2', 'occupation_3', 'occupation_4', 'occupation_5', 'occupation_6', 'occupation_7', 'occupation_8', 'occupation_9', 'occupation_10', 'occupation_11', 'occupation_12', 'occupation_13', 'relationship_0', 'relationship_1', 'relationship_2', 'relationship_3', 'relationship_4', 'relationship_5', 'race_0', 'race_1', 'race_2', 'race_3', 'race_4', 'sex_0', 'sex_1', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country_0', 'native-country_1', 'native-country_2', 'native-country_3', 'native-country_4', 'native-country_5', 'native-country_6', 'native-country_7', 'native-country_8', 'native-country_9', 'native-country_10', 'native-country_11', 'native-country_12', 'native-country_13', 'native-country_14', 'native-country_15', 'native-country_16', 'native-country_17', 'native-country_18', 'native-country_19', 'native-country_20', 'native-country_21', 'native-country_22', 'native-country_23', 'native-country_24', 'native-country_25', 'native-country_26', 'native-country_27', 'native-country_28', 'native-country_29', 'native-country_30', 'native-country_31', 'native-country_32', 'native-country_33', 'native-country_34', 'native-country_35', 'native-country_36', 'native-country_37', 'native-country_38', 'native-country_39', 'native-country_40']\n",
      "Labels: ['<=50K', '>50K']\n"
     ]
    }
   ],
   "source": [
    "# print features and labels\n",
    "print('Features: {}'.format(features))\n",
    "print('Labels: {}'.format(labels))\n",
    "\n",
    "# as you can see this the one-hot encoded version of the data with proper names for the columns/features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94207283  1.          0.          0.          0.          0.\n",
      "  0.          0.          0.          1.12875281  0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.\n",
      "  0.          1.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          1.\n",
      "  1.          0.         -0.1467332  -0.21878026  0.7547014   0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.        ]\n",
      "[1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at some rows of our training data just so we know what it looks like\n",
    "print(train_x[2,:])\n",
    "print(train_y[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] (30 points) Let's tune hyperparameters! We will use scikit-learn in two ways to optimize hyperparameters of SVM: (1) grid search, (2) randomized search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1a] (10 points) Use GridSearchCV from scikit-learn to do a grid search for SVM hyperparameters. Note that this way will use cross-validation to find the best hyperparameters values and that we purposefully disable some warnings to avoid verbose output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C':[0.1, 1, 5], 'penalty': ['l1', 'l2']}\n",
    "model = LinearSVC(max_iter=1000, dual=False)\n",
    "\n",
    "# We'll use this to avoid some annoying convergence warnings \n",
    "# Note: don't just do that without thinking in your own projects, warnings are there for a reason folks!\n",
    "## (In this case, it's okay because it's for illustration, but obviously if the model doesn't converge in \n",
    "## some cases we may not find the true best hyperparams)\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def do_grid_search(model, param_grid):\n",
    "    \n",
    "    # use the GridSearchCV class of scikit-learn to do a grid search on the provided grid (use 'model')\n",
    "    # set accuracy as scoring function and return the output of fit() on the training data\n",
    "    \n",
    "    ###* put your code here (~2 lines) *###\n",
    "    dgs=GridSearchCV(model,param_grid,scoring='accuracy')\n",
    "    return dgs.fit(train_x,train_y)\n",
    "    \n",
    "\n",
    "gs_res = do_grid_search(model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1b] (3 points) How many combination of hyperparameters were tested?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer as comment here *###\n",
    "# The number of hyperparameters that were tested were 6 in total as 3 for 'C' multiplied by 2 for 'penalty'.\n",
    "#\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1c] (2 points) What is the best combination of hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# Show the best combination of parameters found through the search \n",
    "# Hint: look at the documentation of GridSearchCV\n",
    "###* put your code here (~2 lines) *###\n",
    "# store this combination in 'gs_best_hyperparams' and print it\n",
    "gs_best_hyperparams=gs_res.best_params_\n",
    "print(gs_best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1d] (10 points) Use RandomizedSearchCV to do a search! We'll use a halfnormal distribution from Scipy to find values for C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import halfnorm\n",
    "\n",
    "param_dist = dict(C=halfnorm(loc=0, scale=4.0), penalty=['l1', 'l2'])\n",
    "model = LinearSVC(max_iter=1000, dual=False)\n",
    "\n",
    "# We'll use this to avoid some annoying convergence warnings \n",
    "# Note: don't just do that in your own projects, warnings are there for a reason!\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def do_randomized_search(model, param_dist):\n",
    "    # use the RandomizedSearchCV class of scikit-learn to do a randomized search (use 'model')\n",
    "    # use accuracy as scoring function and return the result of fit() on the training data \n",
    "    # Also for reproducibility: set the random_state\n",
    "    \n",
    "    ###* put your code here (~2 lines) *###\n",
    "    drs=RandomizedSearchCV(model,param_dist,scoring='accuracy',random_state=seed)\n",
    "    return drs.fit(train_x,train_y)\n",
    "    \n",
    "    \n",
    "\n",
    "rs_res = do_randomized_search(model, param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-020024ff4ec0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mre_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 're_res' is not defined"
     ]
    }
   ],
   "source": [
    "re_res.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1e] (1 points) What is the best combination of hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.2756087387575334, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the best combination of parameters found through the randomized search \n",
    "###* put your code here (~1 line) *###\n",
    "rs_res.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1f] (4 points) What are the pros and cons of a randomized search? Explain your answer. (A few sentences is okay.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do you think are the pros and cons of a randomized search?\n",
    "###* put your answer as comment here *###\n",
    "# The pros of randomized search are:\n",
    "# It is less time consuming as it only runs on a select randomized sample rather than doing a exhaustive search over the\n",
    "# entire dataset. Generally, in the long run it tends to generate the best results and that too in lesser time.\n",
    "# The cons of randomized search are:\n",
    "# There is a risk of high variance as the selection is totally random and may not cover all possible combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] (10 points) Let's train the model and evaluate it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(w/ best grid search hyperparams {'C': 0.1, 'penalty': 'l1'}): \n",
      "\t--- Training accuracy: 84.99%, Validation accuracy: 84.67%\n"
     ]
    }
   ],
   "source": [
    "# complete the function to calculate accuracy (value in [0,1] range)\n",
    "def model_accuracy(model, x, true_y):\n",
    "    ###* put your code here (~2 lines) *###\n",
    "    pred = model.predict(x)\n",
    "    return np.sum(pred == true_y) / true_y.shape[0]\n",
    "\n",
    "def evaluate_model(name, model, train_x, train_y, val_x, val_y):\n",
    "    train_acc = model_accuracy(model, train_x, train_y)\n",
    "    val_acc = model_accuracy(model, val_x, val_y)\n",
    "    print('{}: \\n\\t--- Training accuracy: {:.2f}%, Validation accuracy: {:.2f}%'.format(name, train_acc*100, val_acc*100))\n",
    "    return\n",
    "    #return train_acc,val_acc\n",
    "\n",
    "###* put your code here (~1 line) *### \n",
    "### Train a LinearSVC using the best hyperparameters found during the grid search in Task 1\n",
    "### In addition you should also use: max_iter=10000, dual=False\n",
    "### Use the training data (train_x, train_y)\n",
    "### Hint: there is a way to pass the best hyperparameters object from Task 1b directly to the model object (i.e., without passing it one hyperparameter at a time)\n",
    "\n",
    "svm=LinearSVC(max_iter=10000,dual=False,random_state=seed,**gs_best_hyperparams)\n",
    "svm.fit(train_x,train_y)\n",
    "evaluate_model('LinearSVC(w/ best grid search hyperparams {})'.format(gs_best_hyperparams), \n",
    "               svm, train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 3] (30 points) Manual Hyperparameter Optimization (i.e., without using scikit-learn's to do the search for us)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3a] (10 points) Complete the code below to do a grid search manually. In this case you cannot use GridSearchCV, you must train and evaluate the model on each combination of hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, hyperparams: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 99.50%, val accuracy: 79.25%\n",
      "Iter 1, hyperparams: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.50%, val accuracy: 79.25%\n",
      "Iter 2, hyperparams: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 89.68%, val accuracy: 81.55%\n",
      "Iter 3, hyperparams: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.52%, val accuracy: 80.80%\n",
      "Iter 4, hyperparams: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 87.40%, val accuracy: 81.84%\n",
      "Iter 5, hyperparams: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.52%, val accuracy: 81.13%\n",
      "Iter 6, hyperparams: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 87.00%, val accuracy: 82.11%\n",
      "Iter 7, hyperparams: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.52%, val accuracy: 81.38%\n",
      "Iter 8, hyperparams: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 85.86%, val accuracy: 82.92%\n",
      "Iter 9, hyperparams: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.52%, val accuracy: 82.02%\n",
      "Iter 10, hyperparams: {'metric': 'euclidean', 'n_neighbors': 51, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 84.14%, val accuracy: 82.84%\n",
      "Iter 11, hyperparams: {'metric': 'euclidean', 'n_neighbors': 51, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.52%, val accuracy: 82.59%\n",
      "Iter 12, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 99.14%, val accuracy: 71.13%\n",
      "Iter 13, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 1, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.14%, val accuracy: 71.13%\n",
      "Iter 14, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 86.54%, val accuracy: 76.47%\n",
      "Iter 15, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 3, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 76.24%\n",
      "Iter 16, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 86.78%, val accuracy: 80.54%\n",
      "Iter 17, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 5, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 79.78%\n",
      "Iter 18, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 85.30%, val accuracy: 80.60%\n",
      "Iter 19, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 7, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 79.96%\n",
      "Iter 20, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 84.54%, val accuracy: 81.11%\n",
      "Iter 21, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 11, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 80.56%\n",
      "Iter 22, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 51, 'weights': 'uniform'}\n",
      " \t-> train accuracy: 82.58%, val accuracy: 81.55%\n",
      "Iter 23, hyperparams: {'metric': 'chebyshev', 'n_neighbors': 51, 'weights': 'distance'}\n",
      " \t-> train accuracy: 99.16%, val accuracy: 81.29%\n"
     ]
    }
   ],
   "source": [
    "## we are allowed to use the following from scikit-learn\n",
    "from sklearn.model_selection import ParameterGrid \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "hyperparams_vals = {'weights': ['uniform', 'distance'],\n",
    "                    'metric': ['euclidean', 'chebyshev'],\n",
    "                    'n_neighbors': [1, 3, 5, 7, 11, 51]}\n",
    "\n",
    "grid = ParameterGrid(hyperparams_vals)\n",
    "\n",
    "trsub_size = 5000\n",
    "trsub_x = train_x[:trsub_size,:]\n",
    "trsub_y = train_y[:trsub_size]\n",
    "\n",
    "## iterate over the entire grid. In each case, train a KNN classifier with the given hyperparameters (on the training subset 'trsub')\n",
    "# and measure accuracy on both the training subset data and the validation data!\n",
    "# note: we use a subset of the training data to speed up the process a bit\n",
    "for i, hyperparams in enumerate(list(grid)):\n",
    "    \n",
    "    ###* put your code here  (~ 5 lines) *###\n",
    "    ### In each iteration of the loop you should train a KNeighborsClassifier using 'hyperparams' as hyperparameters\n",
    "    ### You should train the model on 'trsub_x' and 'trsub_y'!\n",
    "    ### Once your model is trained, compute the accuracy on trsub (training accuracy) and on val (validation accuracy) \n",
    "    ### store the results in 'train_acc' and 'val_acc' respectively\n",
    "    knn=KNeighborsClassifier(**hyperparams)\n",
    "    knn.fit(trsub_x,trsub_y)\n",
    "    train_acc = model_accuracy(knn, trsub_x, trsub_y)\n",
    "    val_acc = model_accuracy(knn, val_x, val_y)\n",
    "    ## This will print information about the grid search as it progresses\n",
    "    print('Iter {}, hyperparams: {}\\n \\t-> train accuracy: {:.2f}%, val accuracy: {:.2f}%'.\n",
    "              format(i, hyperparams, 100*train_acc, 100*val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3b] (5 points) Answer the following questions. (A few sentences is fine.)\n",
    "### What combination of hyperparameters would you use and why? Is the training accuracy useful when doing hyperparameter tuning? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What combination of hyperparameters would you use and why?\n",
    "###* put your answer as comment here *###\n",
    "# The combination which has metric 'euclidean', n_neighbors 11 and weights 'uniform'. This is because it has a high validation\n",
    "# accuracy and relatively similar training accuracy to validation. The model generalises well and fits well onto the data. \n",
    "# Since we have used part of the training data for training, if we use the entire training set this might yield better results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the training accuracy useful when doing hyperparameter tuning? Why or why not?\n",
    "###* put your answer as comment here *###\n",
    "# Yes, it is useful in checking training accuracy when doing hyperparameter tuning. This is because it is helpful in comparing\n",
    "# the hyperparameter combinations, that is checking for each model that is generated from a hyperparameter combination whether the\n",
    "# model is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3d] (10 points) Answer the following questions. (A few sentences is fine.)\n",
    "### Observe what happens when weights changes from 'uniform' to 'distance'? Provide a plausible explanation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you observe in terms of the training and validation accuracies when the weights change from 'uniform' to \n",
    "# 'distance'?\n",
    "###* put your answer as comment here *###\n",
    "# Whenever there is a change from uniform to distance, all other hyperparameters remain same, there is an increase in training\n",
    "# accuracy and decrease in validation accuracy.For the case in which the n_neighbours is 1 both the models are overfitting \n",
    "# regardless of other hyperparameters.\n",
    "\n",
    "\n",
    "## provide a plausible explanation for this phenomenon.\n",
    "###* put your answer as comment here *###\n",
    "#  This shows that whenever there is a change of weights from uniform to distance the model is overfitting with high training\n",
    "# accuracy and relatively low validation accuracy. This is because in distance weighing scheme the weights are assigned  \n",
    "# according to distance and this can lead to a possible exclusion of features in instances which are farther from that may \n",
    "# be important.  \n",
    "\n",
    "## If you were to train a KNN model would you set weights to 'uniform' or 'distance'? Why?\n",
    "###* put your answer as comment here *###\n",
    "# As shown by the accuracies in various hyperparameter combinations that using distance as weight metric has brought the model\n",
    "# to be overfitted when compared to uniform, generally I would be choosing uniform for a better model. But this may also depend on the \n",
    "# data as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3e] (5 points) Which hyperparameters (if any) have a significant impact on overfitting and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### According to the grid search you just performed, which hyperparameters seem to have significant impact on overfitting and why?\n",
    "## Explain your reasoning and justify your answer!\n",
    "###* put your answer as comment here *###\n",
    "# The hyperparameters weights and n_neighbours have significant impact on overfitting. This is because whenever there is a change\n",
    "# of weight from uniform to distance the model overfits. This is due to possible feature exclusion. Also, if the number of \n",
    "# neighbours is low for instance 1, the model overfits irrespective of other hyperparamters. This is due to the fact that since\n",
    "# each instance is a neighbour, the model tries to remember every neighbour for each instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 4] (30 points) Exploring Bias & Variance, Underfitting & Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this task, you *must* only use models (kNN or SVM) and hyperparameters that we have seen/used somewhere in this assignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4a] (5 points) What is the irreducible error for this prediction task (income >=50k or <50k on Adult data)? Explain your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer as comment here *###\n",
    "# The irreducible error for this prediction task might be in the range say 10-15%. This is due to the fact that after training\n",
    "# many models with different combinations of hyperparameters and data sizes, the validation accuracy appears to be less than\n",
    "# 90% which implies that the irreducible error to be more than 10%. This might due to the fact that some inherent noise in\n",
    "# the data that cannot be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the rest of Task 4, we will assume that irreducible error (in the scale 1 - accuracy) is about 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4b] (5 points) Train a high bias, low variance model. Show *and* explain why the model has high bias and low variance! (Use evaluate_model() to calculate and display training accuracy and validation accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_hb_lw: \n",
      "\t--- Training accuracy: 82.58%, Validation accuracy: 81.55%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (~2 lines) *###\n",
    "knn=KNeighborsClassifier(metric= 'chebyshev', n_neighbors= 51, weights='uniform')\n",
    "knn.fit(trsub_x,trsub_y)\n",
    "evaluate_model('knn_hb_lw', knn, trsub_x, trsub_y, val_x, val_y)\n",
    "\n",
    "\n",
    "###* put your answer as comment here *###\n",
    "# This model has high bias and low variance, as the training accuracy and the validation accuracy are similar. This shows that\n",
    "# the model is underfitted so the high bias, this is due to the fact that it is trained with less data. But it generalises \n",
    "# well to the data, so the low variance.\n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4c] (5 points) Train a low bias, high variance model. Show *and* explain why the model has low bias and high variance! (Use evaluate_model() to calculate and display training accuracy and validation accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_lb_hw: \n",
      "\t--- Training accuracy: 99.14%, Validation accuracy: 71.13%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (~2 lines) *###\n",
    "knn=KNeighborsClassifier(metric= 'chebyshev', n_neighbors= 1, weights='distance')\n",
    "knn.fit(trsub_x,trsub_y)\n",
    "evaluate_model('knn_lb_hw', knn, trsub_x, trsub_y, val_x, val_y)\n",
    "\n",
    "###* put your answer as comment here *###\n",
    "# This model has low bias and high variance, as the training accuracy is high and validation accuracy is low. This shows that \n",
    "# the model is overfitted so the low bias but the high variance. The model memorises data well but is not good on the data which\n",
    "# it has not seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4d] (5 points) Train a low bias, low variance model. Show *and* explain why the model has low bias and low variance! (Use evaluate_model() to calculate and display training accuracy and validation accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_lb_lv: \n",
      "\t--- Training accuracy: 98.50%, Validation accuracy: 83.19%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (~2 lines) *###\n",
    "knn1=KNeighborsClassifier(metric= 'euclidean', n_neighbors= 51, weights='distance')\n",
    "knn1.fit(train_x,train_y)\n",
    "evaluate_model('knn_lb_lv',svm1, train_x, train_y, val_x, val_y)\n",
    "###* put your answer as comment here *###\n",
    "# This model has low bias and low variance. This is because, since the irreducible error is assumed to be 15%, \n",
    "# the validation accuracy is as close to the accuracy it can be, so the low variance. The training accuracy is high, \n",
    "# so the low bias.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4e] (5 points) Can you train a high bias, high variance model. If so how? If not why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_hb_hv: \n",
      "\t--- Training accuracy: 97.33%, Validation accuracy: 83.19%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (if applicable) *###\n",
    "#knn1=KNeighborsClassifier(n_neighbors= 1,metric='chebyshev')\n",
    "# knn1.fit(train_x[:10,:],train_y[:10])\n",
    "svm=LinearSVC(max_iter=100,dual=False,C=5,penalty='l2')\n",
    "svm.fit(trsub_x,trsub_y)\n",
    "evaluate_model('knn_hb_hv', knn1, train_x[5000:,:], train_y[5000:], val_x, val_y)\n",
    "\n",
    "\n",
    "###* put your answer as comment here *###\n",
    "# No, I cannot train a high bias, high variance model. After trying a bunch of combinations of models, hyperparameters, and\n",
    "# dataset sizes.I came to this conclusion. This may be due to the fact the inherently when these models try to solve the optimization \n",
    "# problem, there is trade off between the bias and variance everytime even on a case where the dataset is trained on part of \n",
    "# this dataset and tested for training accuracy and validation accuracy on another part of the same.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 4f] (5 points) Train a badly *underfitted* model. The accuracy should be below 55%! (Use evaluate_model() to calculate and display training accuracy and validation accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_uf: \n",
      "\t--- Training accuracy: 53.66%, Validation accuracy: 54.06%\n"
     ]
    }
   ],
   "source": [
    "###* Put your code here (~2 lines) *###\n",
    "knn1=KNeighborsClassifier(n_neighbors= 1,metric='chebyshev')\n",
    "knn1.fit(train_x[:10,:],train_y[:10])\n",
    "evaluate_model('knn_uf', knn1, train_x, train_y, val_x, val_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CIS6930 Additional Task -- Task 5] (25 points): Variance, Overfitting, Agreement Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose we have two models and want to compare them and instead of comparing them in terms of how good the models are, we care about whether the models have learned a similar relationship between features and label? One way we can measure this is using agreement rate: we use both models to make predictions on a separate dataset and then measure what proportion of those predictions are identical.\n",
    "\n",
    "### Variance is the tendency to learn non-existing/wrong relationships between features and labels based on the idiosyncracies of the training data. So intuitively, if two models are trained on disjoint but randomly selected subsets of the training data, then if the variance is high the agreement rate between the two models should be low. So, we can try to measure variance by measuring agreement rate. But does this work? This is what you will explore experimentally in this task. (Note that overfitting and variance are related but are not the same thing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5a] (5 points) Implement an overfitting measure and the agreement rate metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We'll define two metrics, one for overfitting and the other for agreement rate\n",
    "\n",
    "## for this assignment we define overfitting measure as the max between 0 and \n",
    "## the difference between training accuracy and validation accuracy\n",
    "def overfitting_measure(train_acc, val_acc):\n",
    "    ###* put your code here (~1 line) *###\n",
    "    ### your code should return the maxmimum between: 0 and training accuracy - validation accuracy\n",
    "    return max(0,train_acc-val_acc)\n",
    "\n",
    "\n",
    "## the agreement rate is the proportion of identical prediction of both models on a separate dataset\n",
    "## note: we don't care if the predictions are correct, we only care how often they are the same!\n",
    "def agreement_rate(m1_preds, m2_preds):\n",
    "    assert m1_preds.shape == m2_preds.shape\n",
    "    \n",
    "    ###* put your code here (~1 line) *###\n",
    "    ### your code should return the proportion of identical predictions in m1_preds and m2_preds\n",
    "    ### note: the agreement rate is a value in [0, 1] so make sure your code returns values in the same range!\n",
    "    return np.sum(m1_preds == m2_preds) / m2_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def eval_accuracy(model, train_x, train_y, val_x, val_y):\n",
    "    train_acc = model_accuracy(model, train_x, train_y)\n",
    "    val_acc = model_accuracy(model, val_x, val_y)\n",
    "    \n",
    "    return train_acc, val_acc\n",
    "\n",
    "def measure_overfitting_agreement(model, train_x, train_y, trsz, val_x, val_y):\n",
    "    m1 = clone(model)\n",
    "    m2 = clone(model)\n",
    "    \n",
    "    n = train_x.shape[0]\n",
    "    assert n/2 >= trsz and trsz > 0\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    pi = rng.permutation(n)\n",
    "    pi1 = pi[0:trsz]\n",
    "    pi2 = pi[trsz:2*trsz]\n",
    "    \n",
    "    m1.fit(train_x[pi1], train_y[pi1])\n",
    "    m2.fit(train_x[pi2], train_y[pi2])\n",
    "    \n",
    "    train_acc, val_acc = eval_accuracy(m1, train_x[pi1], train_y[pi1], val_x, val_y)\n",
    "    m1_overfit =  np.maximum(0, train_acc - val_acc)\n",
    "    \n",
    "    train_acc, val_acc = eval_accuracy(m2, train_x[pi2], train_y[pi2], val_x, val_y)\n",
    "    m2_overfit =  np.maximum(0, train_acc - val_acc)\n",
    "    \n",
    "    m1_val_pred = m1.predict(val_x)\n",
    "    m2_val_pred = m2.predict(val_x)\n",
    "    \n",
    "    agr = agreement_rate(m1_val_pred, m2_val_pred)\n",
    "    \n",
    "    # for this task, we'll define our our overfitting measure as \n",
    "    # the average of the overfitting measure of the two models\n",
    "    overfit = (m1_overfit + m2_overfit)/2.0 \n",
    "    \n",
    "    return overfit, agr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5b] (10 points) Train SVM models on random subsets of the data with different C (regularization constant) and two different size for the training data. In each case, use measure_overfitting_agreement() defined above to train the models and compute overfitting and agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(-2,3,200)\n",
    "training_sizes = [100, 200]\n",
    "\n",
    "###* put your code here *###\n",
    "### your code should use 'SVC(C=<value from Cs>, kernel='linear')' as model instances\n",
    "### You should invoke measure_overfitting_agreement() to get the agreement rate and overfitting measure \n",
    "### (do this for all values in 'Cs' and both training sizes)\n",
    "### and store the results in some array(s) of your choice so that you can plot this for Task 5c\n",
    "output=[]\n",
    "for i in range(0,len(training_sizes)):\n",
    "    l=[]\n",
    "    r=[]\n",
    "    for c in Cs:\n",
    "        svm=SVC(C=c,kernel='linear')\n",
    "        l.append(measure_overfitting_agreement(svm, train_x, train_y, trsz, val_x, val_y)[0])\n",
    "        r.append(measure_overfitting_agreement(svm, train_x, train_y, trsz, val_x, val_y)[1])\n",
    "    output.append(l)\n",
    "    output.append(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for disagreement rate of 100 training size \n",
    "for i in range(0,len(output[1])):\n",
    "    output[1][i]=1-output[1][i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5c] (5 points) Plot overfitting vs disagreement rate as a scatter plot for both training sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for disagreement rate of 200 training size \n",
    "for i in range(0,len(output[3])):\n",
    "    output[3][i]=1-output[3][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Use matplotlib and supplement the provided code so it produces a single scatter plot of the two training set sizes\n",
    "### with overfitting on the x-axis and *disagreement* (i.e., 1 - agreement rate) on the y-axis.\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "\n",
    "###* put your code here (~2 lines) *###\n",
    "### Invoke plt.scatter() first for Training Set Size: 100; use blue circle marker.\n",
    "### Invoke plt.scatter() again this time for Training Set Size: 200; use red square marker.\n",
    "plt.scatter(output[0],output[1],c='blue',label='Training Set Size: 100')\n",
    "plt.scatter(output[2],output[3],c='red',label='Training Set Size: 200')\n",
    "\n",
    "\n",
    "## sets the axis labels, limits, etc.\n",
    "plt.xlabel('Overfitting Measure')\n",
    "plt.ylabel('Disagreement Rate (1 - Agreement Rate)')\n",
    "plt.xlim([-0.02, 0.3])\n",
    "plt.ylim([-0.02, 0.45])\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5d] (5 points) What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you conclude? Is agreement rate a possible way to measure overfitting? Can it be used to measure variance?\n",
    "# Describe your general observation of the correlation between these measures.\n",
    "# Hint: there is no single 'right' answer here, but there are many wrong answers!\n",
    "###* put your answer as comment here *###\n",
    "# Observing from the graph, considering the two subsets, I think that the agreement rate is correlated to overfitting measure.\n",
    "# But, I dont think that agreement rate to be a possible way to measure overfitting or even variance. This is because \n",
    "# it is highly dependent on the subsets which are taken into consideration and its size. For instance, even if the overall \n",
    "# variance is high, if both subsets which are taken have a uniform and representative, the agreement rate would be high,\n",
    "# but when both are non uniform or representative, then the agreement rate would be low.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
